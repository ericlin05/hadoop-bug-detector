Description

Currently, spark driver exceptions are not getting logged in beeline. Instead, the users sees the not-so-useful: 


ERROR : Failed to execute spark task, with exception 'org.apache.hadoop.hive.ql.metadata.HiveException(Failed to create spark client.)'
&amp;lt;huge stack trace ommitted&amp;gt;


The user has to look at HS2 logs to discover the root cause:


2015-04-01 11:33:16,048 INFO org.apache.hive.spark.client.SparkClientImpl: 15/04/01 11:33:16 WARN UserGroupInformation: PriviledgedActionException as:foo (auth:PROXY) via hive (auth:SIMPLE) cause:org.apache.hadoop.security.AccessControlException: Permission denied: user=foo, access=WRITE, inode="/user":hdfs:supergroup:drwxr-xr-x
...


We should surface these critical errors in hive client.


